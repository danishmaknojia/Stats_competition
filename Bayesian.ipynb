{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, BayesianRidge\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pd.read_csv('../Stats_competition-/final_opponent_and_team_data.csv')\n",
    "team_data['Location'] = np.where(team_data['Location'] == 'N', 0, np.where(team_data['Location'] == 'H', 1, -1))\n",
    "columns_to_convert = ['Location','ADJO', 'ADJD', 'EFG%', 'TO%', 'OR%', 'FTR', 'Opp EFG%', 'Opp TO%', 'Opp OR%', 'Opp FTR']\n",
    "for col in columns_to_convert:\n",
    "    team_data[col] = pd.to_numeric(team_data[col], errors='coerce')\n",
    "    \n",
    "cleanDate = team_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns not needed for predictions\n",
    "feature_cols = cleanDate.columns.difference(['Date', 'Team', 'Opponent', 'Team_score', 'Opponent_score',\n",
    "                                             '2P', '3P', 'Opp 2P', 'Opp 3P',\n",
    "                                             'EFF', 'Opp EFF', 'WAB'])\n",
    "\n",
    "# Defining the feature matrix (X) and target matrix (y)\n",
    "X = cleanDate[feature_cols]\n",
    "y = cleanDate[['Team_score', 'Opponent_score']]\n",
    "\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Bayesian Ridge regression models for multiple target variables without evaluation.\n",
    "def train_BaseModel(X, y):\n",
    "    models = {}\n",
    "    for target in y.columns:\n",
    "        print(f\"Training model for {target}...\")\n",
    "\n",
    "        # Initialize the model\n",
    "        model = BayesianRidge()\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X, y[target])\n",
    "        models[target] = model\n",
    "\n",
    "        print(f\"Model for {target} trained successfully.\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "# Train a StackingRegressor for multiple target variables without evaluation.\n",
    "def train_EnsembleModel(X, y, threshold=6):\n",
    "    models = {}\n",
    "    for target in y.columns:\n",
    "        print(f\"Training StackingRegressor model for {target}...\")\n",
    "\n",
    "        # Define base models and stacking regressor\n",
    "        base_models = [\n",
    "            ('ridge', Ridge()),\n",
    "            ('bayesian_ridge', BayesianRidge())\n",
    "        ]\n",
    "        stacking_model = StackingRegressor(estimators=base_models, final_estimator=BayesianRidge())\n",
    "\n",
    "        # Train the stacking model\n",
    "        stacking_model.fit(X, y[target])\n",
    "        models[target] = stacking_model\n",
    "\n",
    "        print(f\"Model for {target} trained successfully.\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# Train a StackingRegressor combining Bayesian Ridge and Random Forest for multiple target variables.\n",
    "def train_EnsembleModelWithRF(X_train, y_train, threshold=6):\n",
    "    models = {}\n",
    "    for target in y_train.columns:\n",
    "        print(f\"Training StackingRegressor model for {target}...\")\n",
    "\n",
    "        # Define base models and stacking regressor\n",
    "        base_models = [\n",
    "            ('bayesian_ridge', BayesianRidge()),\n",
    "            ('random_forest', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "        ]\n",
    "        stacking_model = StackingRegressor(estimators=base_models, final_estimator=BayesianRidge())\n",
    "\n",
    "        # Train the stacking model\n",
    "        stacking_model.fit(X_train, y_train[target])\n",
    "        models[target] = stacking_model\n",
    "\n",
    "        print(f\"Model for {target} trained successfully.\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "# Train Bayesian Ridge regression models with hyperparameter tuning for multiple target variables.\n",
    "def train_baseModelWithHyperparameterTuning(X_train, y_train, threshold=6):\n",
    "    models = {}\n",
    "\n",
    "    for target in y_train.columns:\n",
    "        print(f\"Training model for {target}...\\n\")\n",
    "\n",
    "        # Step 1: Broad parameter ranges for RandomizedSearchCV\n",
    "        random_param_grid = {\n",
    "            'alpha_1': np.logspace(-6, -2, 20),  # Wide range\n",
    "            'alpha_2': np.logspace(-6, -2, 20),  # Wide range\n",
    "            'lambda_1': np.logspace(-6, -2, 20), # Wide range\n",
    "            'lambda_2': np.logspace(-6, -2, 20), # Wide range\n",
    "            'tol': [1e-4, 1e-3, 1e-2],\n",
    "            'max_iter': [100, 300, 500]\n",
    "        }\n",
    "\n",
    "        model = BayesianRidge()\n",
    "        scorer = 'neg_mean_squared_error'\n",
    "\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model, random_param_grid, scoring=scorer, cv=5, n_iter=50, verbose=1, random_state=42\n",
    "        )\n",
    "        random_search.fit(X_train, y_train[target])\n",
    "        best_params_random = random_search.best_params_\n",
    "        print(f\"Best parameters from RandomizedSearchCV for {target}:\", best_params_random)\n",
    "\n",
    "        # Step 2: Define a narrower grid around the best parameters\n",
    "        grid_param_grid = {\n",
    "            'alpha_1': np.linspace(\n",
    "                best_params_random['alpha_1'] / 10, best_params_random['alpha_1'] * 10, 10\n",
    "            ),\n",
    "            'alpha_2': np.linspace(\n",
    "                best_params_random['alpha_2'] / 10, best_params_random['alpha_2'] * 10, 10\n",
    "            ),\n",
    "            'lambda_1': np.linspace(\n",
    "                best_params_random['lambda_1'] / 10, best_params_random['lambda_1'] * 10, 10\n",
    "            ),\n",
    "            'lambda_2': np.linspace(\n",
    "                best_params_random['lambda_2'] / 10, best_params_random['lambda_2'] * 10, 10\n",
    "            ),\n",
    "            'tol': [1e-4, 1e-3, 1e-2],\n",
    "            'max_iter': [100, 300, 500]\n",
    "        }\n",
    "\n",
    "        grid_search = GridSearchCV(model, grid_param_grid, scoring=scorer, cv=5, verbose=1)\n",
    "        grid_search.fit(X_train, y_train[target])\n",
    "        best_params_grid = grid_search.best_params_\n",
    "        print(f\"Best parameters from GridSearchCV for {target}:\", best_params_grid)\n",
    "\n",
    "        # Step 3: Train the model with the best parameters\n",
    "        final_model = BayesianRidge(**best_params_grid)\n",
    "        final_model.fit(X_train, y_train[target])\n",
    "        models[target] = final_model\n",
    "\n",
    "        print(f\"Model for {target} trained successfully.\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "model1 = train_BaseModel(X, y)\n",
    "print(model1)\n",
    "\n",
    "model2 = train_EnsembleModel(X, y)\n",
    "print(model2)\n",
    "\n",
    "model3 = train_EnsembleModelWithRF(X, y)\n",
    "print(model3)\n",
    "\n",
    "model4 = train_baseModelWithHyperparameterTuning(X, y)\n",
    "print(model4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictModel(models, data):\n",
    "    # Preprocess the data\n",
    "    print(\"Preprocessing data for prediction...\")\n",
    "    data['Location'] = np.where(data['Location'] == 'Neutral', 0, \n",
    "                                np.where(data['Location'] == 'Home', 1, -1))\n",
    "    \n",
    "    columns_to_convert = ['ADJD', 'ADJO', 'EFG%', 'FTR', 'Location', 'OR%', \n",
    "                        'Opp EFG%', 'Opp FTR', 'Opp OR%', 'Opp TO%', 'TO%',\n",
    "                        'opp_adj_d', 'opp_adj_o']\n",
    "    \n",
    "    for col in columns_to_convert:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    \n",
    "    \n",
    "    # Extract the features for prediction\n",
    "    X = data[columns_to_convert]\n",
    "\n",
    "    # Make predictions using the models\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = pd.DataFrame()\n",
    "    for target, model in models.items():\n",
    "        print(f\"Predicting {target}...\")\n",
    "        predictions[target] = model.predict(X)\n",
    "\n",
    "    print(\"Predictions completed.\\n\")\n",
    "    \n",
    "    teams = data[['Team', 'Opponent']]\n",
    "    finalPredictions = pd.concat([teams, predictions], axis=1)\n",
    "    \n",
    "    return finalPredictions\n",
    "\n",
    "predict_data = pd.read_csv('../Stats_competition-/basketball_games_data.csv')\n",
    "predict1 = predictModel(model1, predict_data)\n",
    "predict2 = predictModel(model2, predict_data)\n",
    "predict3 = predictModel(model3, predict_data)\n",
    "predict4 = predictModel(model4, predict_data)\n",
    "\n",
    "predict1 = predict1.rename(columns={'Team_score': 'Team_score_base', 'Opponent_score': 'Opponent_score_base'})\n",
    "predict2 = predict2.rename(columns={'Team_score': 'Team_score_ensemble', 'Opponent_score': 'Opponent_score_ensemble'})\n",
    "predict3 = predict3.rename(columns={'Team_score': 'Team_score_ensembleRF', 'Opponent_score': 'Opponent_score_ensembleRF'})\n",
    "predict4 = predict4.rename(columns={'Team_score': 'Team_score_fineTuned', 'Opponent_score': 'Opponent_score_fineTuned'})\n",
    "\n",
    "# Join all four DataFrames on 'team' and 'opponent'\n",
    "dfFinalPrediction1 = predict1.merge(predict2, on=['Team', 'Opponent'], how='outer')\n",
    "dfFinalPrediction2 = predict3.merge(predict4, on=['Team', 'Opponent'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfFinalPrediction1)\n",
    "display(dfFinalPrediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Bayesian Ridge regression models for multiple target variables.\n",
    "def baseModel(X_train, y_train, X_test, y_test, threshold=6):\n",
    "    models = {}\n",
    "    for target in y_train.columns:\n",
    "        print(f\"Training model for {target}...\")\n",
    "\n",
    "        # Initialize the model\n",
    "        model = BayesianRidge()\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train[target])\n",
    "        models[target] = model\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate accuracy within the threshold\n",
    "        accuracy = (abs(y_pred - y_test[target]) <= threshold).mean() * 100\n",
    "        print(f\"Accuracy for {target} within {threshold} points: {accuracy:.2f}%\")\n",
    "\n",
    "        # Evaluate RMSE\n",
    "        rmse = mean_squared_error(y_test[target], y_pred, squared=False)\n",
    "        print(f\"RMSE for {target}: {rmse:.4f}\\n\")\n",
    "\n",
    "        # Optional: Uncomment to print predictions\n",
    "        # print(\"Actual:\", y_test[target].values)\n",
    "        # print(\"Predicted values:\", y_pred)\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model_main = baseModel(X_train, y_train, X_test, y_test)\n",
    "print(model_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnsembleModel(X_train, y_train, X_test, y_test, threshold=6):\n",
    "    \"\"\"\n",
    "    Train and evaluate a StackingRegressor for multiple target variables.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (DataFrame): Training feature set.\n",
    "    y_train (DataFrame): Training target set (multi-target).\n",
    "    X_test (DataFrame): Test feature set.\n",
    "    y_test (DataFrame): Test target set (multi-target).\n",
    "    threshold (int, optional): Threshold for accuracy evaluation. Default is 6.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing trained ensemble models for each target variable.\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    for target in y_train.columns:\n",
    "        print(f\"Training StackingRegressor model for {target}...\")\n",
    "\n",
    "        # Define base models and stacking regressor\n",
    "        base_models = [\n",
    "            ('ridge', Ridge()),\n",
    "            ('bayesian_ridge', BayesianRidge())\n",
    "        ]\n",
    "        stacking_model = StackingRegressor(estimators=base_models, final_estimator=BayesianRidge())\n",
    "\n",
    "        # Train the stacking model\n",
    "        stacking_model.fit(X_train, y_train[target])\n",
    "        models[target] = stacking_model\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "        # Evaluate accuracy within the threshold\n",
    "        accuracy = (abs(y_pred - y_test[target]) <= threshold).mean() * 100\n",
    "        print(f\"Accuracy for {target} within {threshold} points: {accuracy:.2f}%\")\n",
    "\n",
    "        # Evaluate RMSE\n",
    "        rmse = mean_squared_error(y_test[target], y_pred, squared=False)\n",
    "        print(f\"RMSE for {target}: {rmse:.4f}\\n\")\n",
    "\n",
    "        # Optional: Uncomment to print predictions\n",
    "        # print(\"Actual:\", y_test[target].values)\n",
    "        # print(\"Predicted values:\", y_pred)\n",
    "\n",
    "    return models\n",
    "\n",
    "# Example Usage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model2 = EnsembleModel(X_train, y_train, X_test, y_test)\n",
    "print(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and evaluate a StackingRegressor combining Bayesian Ridge and Random Forest for multiple target variables.\n",
    "\n",
    "def EnsembleModelWithRF(X_train, y_train, X_test, y_test, threshold=6):\n",
    "    models = {}\n",
    "    for target in y_train.columns:\n",
    "        print(f\"Training StackingRegressor model for {target}...\")\n",
    "\n",
    "        # Define base models and stacking regressor\n",
    "        base_models = [\n",
    "            ('bayesian_ridge', BayesianRidge()),\n",
    "            ('random_forest', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "        ]\n",
    "        stacking_model = StackingRegressor(estimators=base_models, final_estimator=BayesianRidge())\n",
    "\n",
    "        # Train the stacking model\n",
    "        stacking_model.fit(X_train, y_train[target])\n",
    "        models[target] = stacking_model\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "        # Evaluate accuracy within the threshold\n",
    "        accuracy = (abs(y_pred - y_test[target]) <= threshold).mean() * 100\n",
    "        print(f\"Accuracy for {target} within {threshold} points: {accuracy:.2f}%\")\n",
    "\n",
    "        # Evaluate RMSE\n",
    "        rmse = mean_squared_error(y_test[target], y_pred, squared=False)\n",
    "        print(f\"RMSE for {target}: {rmse:.4f}\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "# Example Usage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model3 = EnsembleModelWithRF(X_train, y_train, X_test, y_test)\n",
    "print(model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Bayesian Ridge regression models for multiple target variables\n",
    "def baseModelWithHyperparameterTuning(X_train, y_train, X_test, y_test, threshold=6):\n",
    "    models = {}\n",
    "    \n",
    "    for target in y_train.columns:\n",
    "        print(f\"Training model for {target}...\\n\")\n",
    "\n",
    "        # Step 1: Broad parameter ranges for RandomizedSearchCV\n",
    "        random_param_grid = {\n",
    "            'alpha_1': np.logspace(-6, -2, 20),  # Wide range\n",
    "            'alpha_2': np.logspace(-6, -2, 20),  # Wide range\n",
    "            'lambda_1': np.logspace(-6, -2, 20), # Wide range\n",
    "            'lambda_2': np.logspace(-6, -2, 20), # Wide range\n",
    "            'tol': [1e-4, 1e-3, 1e-2],\n",
    "            'max_iter': [100, 300, 500]\n",
    "        }\n",
    "        \n",
    "        model = BayesianRidge()\n",
    "        scorer = 'neg_mean_squared_error'\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            model, random_param_grid, scoring=scorer, cv=5, n_iter=50, verbose=1, random_state=42\n",
    "        )\n",
    "        random_search.fit(X_train, y_train[target])\n",
    "        best_params_random = random_search.best_params_\n",
    "        print(f\"Best parameters from RandomizedSearchCV for {target}:\", best_params_random)\n",
    "        \n",
    "        # Step 2: Define a narrower grid around the best parameters\n",
    "        grid_param_grid = {\n",
    "            'alpha_1': np.linspace(\n",
    "                best_params_random['alpha_1'] / 10, best_params_random['alpha_1'] * 10, 10\n",
    "            ),\n",
    "            'alpha_2': np.linspace(\n",
    "                best_params_random['alpha_2'] / 10, best_params_random['alpha_2'] * 10, 10\n",
    "            ),\n",
    "            'lambda_1': np.linspace(\n",
    "                best_params_random['lambda_1'] / 10, best_params_random['lambda_1'] * 10, 10\n",
    "            ),\n",
    "            'lambda_2': np.linspace(\n",
    "                best_params_random['lambda_2'] / 10, best_params_random['lambda_2'] * 10, 10\n",
    "            ),\n",
    "            'tol': [1e-4, 1e-3, 1e-2],\n",
    "            'max_iter': [100, 300, 500]\n",
    "        }\n",
    "        \n",
    "        grid_search = GridSearchCV(model, grid_param_grid, scoring=scorer, cv=5, verbose=1)\n",
    "        grid_search.fit(X_train, y_train[target])\n",
    "        best_params_grid = grid_search.best_params_\n",
    "        print(f\"Best parameters from GridSearchCV for {target}:\", best_params_grid)\n",
    "        \n",
    "        # Step 3: Train the model with the best parameters\n",
    "        final_model = BayesianRidge(**best_params_grid)\n",
    "        final_model.fit(X_train, y_train[target])\n",
    "        models[target] = final_model\n",
    "\n",
    "        # Step 4: Make predictions\n",
    "        y_pred = final_model.predict(X_test)\n",
    "\n",
    "        # Evaluate accuracy within the threshold\n",
    "        accuracy = (abs(y_pred - y_test[target]) <= threshold).mean() * 100\n",
    "        print(f\"Accuracy for {target} within {threshold} points: {accuracy:.2f}%\")\n",
    "\n",
    "        # Evaluate RMSE\n",
    "        rmse = mean_squared_error(y_test[target], y_pred, squared=False)\n",
    "        print(f\"RMSE for {target}: {rmse:.4f}\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate the model\n",
    "model_main = baseModelWithHyperparameterTuning(X_train, y_train, X_test, y_test)\n",
    "print(model_main)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
